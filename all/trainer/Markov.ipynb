{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4um0KIiEmcC",
        "outputId": "a2de78f1-ec4e-4b9e-ddaa-e1926829221c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gz2Y6EhGCts2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9yUEvaPDDwR",
        "outputId": "5bf22a2b-43e2-4359-fed2-964c4ae1d90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7HV3_idDHLM",
        "outputId": "5d37c3c0-a300-4eec-dab0-aa1634bcc192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 evaluate-0.4.0 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK0B-TPHCts3"
      },
      "source": [
        "## Section-1: Dataset Manipulation\n",
        "---\n",
        "The following main goals are achieved in this section:\n",
        "  - Dataset is loaded\n",
        "  - Uninteresting lines are deleted from the dataset\n",
        "  - Lines are converted into a list of string for further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KwkmeHMPCts3",
        "outputId": "1239a75e-0ff7-4097-fa50-2f3aa6ae0035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                            content  \\\n",
              "0  139248  ngày đông se sắt lạnh trong lòng\\ncó việc đi n...   \n",
              "1  139249  ôm đàn thao thức đến nữa đêm\\nréo rắt cung âm ...   \n",
              "2  139250  tết có người vui có kẻ buồn\\nngười cười toe to...   \n",
              "3  139251  đã quá ba mươi mộng lỡ làng\\nđi tìm day dứt mả...   \n",
              "4  139252  mai đào nở rộ đón nàng xuân\\nsợi nắng hanh vàn...   \n",
              "\n",
              "                 title                                                url  \\\n",
              "0             SAY NẮNG  https://www.facebook.com/groups/48640773509859...   \n",
              "1                  NaN  https://www.facebook.com/groups/17645444269765...   \n",
              "2     TẾT HAI THÁI CỰC  https://www.facebook.com/groups/17645444269765...   \n",
              "3  TRÁI NGANG ĐỨC HẠNH  https://www.facebook.com/groups/48640773509859...   \n",
              "4            DÁNG XUÂN  https://www.facebook.com/groups/17645444269765...   \n",
              "\n",
              "   genre  \n",
              "0  7 chu  \n",
              "1  7 chu  \n",
              "2  7 chu  \n",
              "3  7 chu  \n",
              "4  7 chu  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58502710-5511-4176-9ac8-35217b9b2b69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>139248</td>\n",
              "      <td>ngày đông se sắt lạnh trong lòng\\ncó việc đi n...</td>\n",
              "      <td>SAY NẮNG</td>\n",
              "      <td>https://www.facebook.com/groups/48640773509859...</td>\n",
              "      <td>7 chu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139249</td>\n",
              "      <td>ôm đàn thao thức đến nữa đêm\\nréo rắt cung âm ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.facebook.com/groups/17645444269765...</td>\n",
              "      <td>7 chu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139250</td>\n",
              "      <td>tết có người vui có kẻ buồn\\nngười cười toe to...</td>\n",
              "      <td>TẾT HAI THÁI CỰC</td>\n",
              "      <td>https://www.facebook.com/groups/17645444269765...</td>\n",
              "      <td>7 chu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>139251</td>\n",
              "      <td>đã quá ba mươi mộng lỡ làng\\nđi tìm day dứt mả...</td>\n",
              "      <td>TRÁI NGANG ĐỨC HẠNH</td>\n",
              "      <td>https://www.facebook.com/groups/48640773509859...</td>\n",
              "      <td>7 chu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>139252</td>\n",
              "      <td>mai đào nở rộ đón nàng xuân\\nsợi nắng hanh vàn...</td>\n",
              "      <td>DÁNG XUÂN</td>\n",
              "      <td>https://www.facebook.com/groups/17645444269765...</td>\n",
              "      <td>7 chu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58502710-5511-4176-9ac8-35217b9b2b69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58502710-5511-4176-9ac8-35217b9b2b69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58502710-5511-4176-9ac8-35217b9b2b69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "df = pd.read_csv ('poems_dataset.csv')\n",
        "df.head ()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_list = df['genre'].tolist()\n",
        "genre_list = list( dict.fromkeys(genre_list) )\n",
        "\n",
        "print(genre_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH-tjDDuMqT1",
        "outputId": "5640529f-b01d-48c2-bfc4-6f5f071c6704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['7 chu', 'luc bat', '8 chu', '5 chu', '4 chu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1i2VF--Cts4",
        "outputId": "a0aff9d1-cbfe-496a-cc2a-88c943f8f56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87605\n"
          ]
        }
      ],
      "source": [
        "df = df.loc[df['genre'] == 'luc bat']\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=0.12)\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4_JOV7MReT9",
        "outputId": "8d63a4b4-f907-471d-8b8a-5312b6d497ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49hebuAwCts4",
        "outputId": "bc777aa6-9c13-4e5e-d21e-7d5e69a0ebd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['đêm qua trời nổi cơn dông\\nmưa như trút nước cánh đồng làng ta\\nđược tin mất bác mối già\\nhọ hàng nhà mối kéo ra từng đàn\\n\\ncon nào cũng trắng áo tang\\nkéo cả họ hàng mối để tiễn đưa\\nsáng nay trời đã tạnh mưa\\nhàng xóm gần gũi cũng vừa biết tin\\n\\nkiến vàng kiến cánh kiến kim\\ntừng đàn kéo đến cũng xin chia buồn\\nsườn đê mấy bác chuồn chuồn\\nlượn qua lượn lại chia buồn tiễn đưa\\n\\nđám tang kéo tận tới trưa\\nqua bờ kênh nhỏ đắp vừa hôm qua\\ntiếc thương tiễn bác mối già\\nhọ hàng nhà mối đưa ra ngoài đồng\\n\\ngò cao nghĩa địa mênh mông\\nđặt nơi yên nghỉ cho ông mối già\\nlùm xùm cũng mấy cây hoa\\nlà nơi an táng làng ta vẫn làm', 'mỗi khi nhắc đến cái nghèo\\nngười ta liền nghĩ cái vèo thiếu ăn\\nít ai nghĩ chuyện xa xăm\\nnghèo ngay trong cả chính tâm hồn mình\\n\\ncon người từ buổi sơ sinh\\nnhu cầu sự sống chỉ vin sữa sùng\\nsinh vật tồn tại chung chung\\ncũng nhờ dinh dưỡng bổ sung hàng ngày\\nnguyên lý đời sống xưa nay\\nkhông hề thay đổi theo dài thời gian\\nchỉ khi lão hoá suy tàn\\nhay là tai họa ngưng ngang nhu cầu\\n\\ncon người có khác gì đâu\\nphải theo quy luật bao lâu sống đời\\ncho nên mọi lúc mọi nơi\\nngười nào mà chẳng lội bơi kiếm tìm\\ncái ăn cái mặc ngày đêm\\nđấu tranh giành giật có thêm từng giờ\\nsống là không thể ơ thờ\\nbi quan thụ động ngồi chờ ai cho\\n\\nnhưng mà không chỉ ấm no\\nhọ còn nhiều việc phải lo hàng ngày\\ncái ăn cái ở cái xài\\nlo con lo cái lo ngoài lo trong\\nđói nghèo thiếu thốn long đong\\nlà nỗi ám ảnh phập phồng thế nhân\\nkhông phải chỉ sợ khổ thân\\nmà còn sỉ diện khổ tâm với đời\\nai người chẳng muốn thảnh thơi\\ndư ăn dư mặc rong chơi thỏa lòng\\nnhưng rồi có được hay không\\nhay là nghèo khổ quanh năm vẫn nghèo\\n\\nnghèo tiền nghèo bạc nhóc nheo\\nthiếu cơm thiếu áo tong teo gầy còm\\ndù vậy đừng để tâm hồn\\nvô ân vô cảm chai sờn nhân văn\\nở đời đâu chỉ cái ăn\\ncần có cảm xúc cân bằng trong ta\\nsống thì phải biết vị tha\\ntham lam ích kỷ chỉ là tiện nhân\\n\\ngiàu nghèo cũng phải tu thân\\ntrau dồi đức hạnh nghĩa nhân giữ lòng\\nloài người khác với thú cầm\\nvì có xúc cảm con tim cháy bùng', 'bên thềm trăng ngó tâm tư\\nđếm từng nốt nhạc thả từ hồn ai\\ntiếng tơ ngắt quãng đêm dài\\ncung trầm ríu lại gửi ai nỗi sầu\\n\\ngió ơi cõng thiếp mấy câu\\nvo tròn ôm chặt qua cầu chớ rơi\\ntrăng đang đi ẩn sao ơi\\nngó nghiêng chút nữa cho vơi nét buồn\\n\\nthuyền ơi chờ gió căng buồm\\nsao ôm con sóng nước cuồn cuộn reo\\nlênh đênh buông thả mái chèo\\nbến yên gió lặng thuyền neo giữa dòng', 'cuộc đời có lúc không suôn\\nnhưng giờ thì mọi chuyện buồn đã qua\\nmình vui vẻ muốn chan hoà\\nlàm thơ xướng hoạ để mà được vui\\nmong các bạn đừng ngậm ngùi\\nmình làm thơ để góp vui cho đời\\nkhông hề ngộ nhận bạn ơi\\nvui thì kể lại bạn buồn thì thôi\\nsau này thơ giỏi thật rồi\\nmới đem viết truyện để ngồi đọc chơi', 'mênh mang thơ trải đất trời\\ntình thơ gởi tặng những người bạn yêu\\ntâm hồn bay bổng phiêu diêu\\ntrái tim gói trọn bao điều ước mơ\\nthơ là gió mát ban trưa\\nlà mây bay đến lời ru giấc nồng']\n"
          ]
        }
      ],
      "source": [
        "lines = df['content'].tolist ()\n",
        "print(lines [:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itFjTFrOCts5"
      },
      "outputs": [],
      "source": [
        "# The length of lines generated based on HMM is restricted to this value.\n",
        "# It is a safeguard to protect the code from a potential infinite loop\n",
        "MAX_LINE_LENGTH = 8\n",
        "\n",
        "# This is used to check the equality of two floating point values. If\n",
        "# their difference is less than this value, they are considered equal\n",
        "FLOAT_DELTA = 0.0001\n",
        "\n",
        "# This special string is used to mark the end of a sentence\n",
        "END_TOKEN = 'endl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18KNnIUlCts5"
      },
      "source": [
        "### Section-2.2: Helper Functions for Text-Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NQEI3q8sCts5"
      },
      "outputs": [],
      "source": [
        "# Remove white-spaces and punctuations from a line and convert it\n",
        "# into a list of tokens\n",
        "def tokenize (line):\n",
        "    baseline = line.strip ().lower ()\n",
        "    tokens = ''.join ([x for x in baseline if x not in string.punctuation]).split ()\n",
        "    return tokens\n",
        "\n",
        "# Add a pairing to dictionary\n",
        "def insert_link (dictionary, key, value, debug = False):\n",
        "    if key not in dictionary:\n",
        "        dictionary [key] = []\n",
        "    if debug: print(key, dictionary [key])\n",
        "    dictionary [key].append (value)\n",
        "\n",
        "# Convert list to probability values\n",
        "def to_probability (chain):\n",
        "    frequencies = {}\n",
        "    probabilities = {}\n",
        "    num_of_words = len (chain)\n",
        "\n",
        "    for word in chain:\n",
        "        frequencies [word] = frequencies.get (word, 0) + 1\n",
        "\n",
        "    for word, frequency in frequencies.items ():\n",
        "        probabilities [word] = round (float (frequency) / num_of_words, 3)\n",
        "\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM4FiGOrCts5"
      },
      "source": [
        "### Section-2.3: Main Function for Building the Markov Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bnKvyf5CCts6"
      },
      "outputs": [],
      "source": [
        "def build_markov_model (corpus, first_order_markov_chain, second_order_markov_chain):\n",
        "    # This is a dictionary of words which have been used to\n",
        "    # start a line in Shakespeare's plays\n",
        "    words = []\n",
        "\n",
        "    for line in corpus:\n",
        "        tokens = tokenize (line)\n",
        "        num_of_tokens = len (tokens)\n",
        "\n",
        "        for idx in range (num_of_tokens):\n",
        "            token = tokens [idx]\n",
        "\n",
        "            if idx == 0:\n",
        "                words.append (token)\n",
        "\n",
        "                # We are not interested in the first word of a\n",
        "                # line since nothing precedes it\n",
        "                continue\n",
        "\n",
        "            # Populate first-order markov chain\n",
        "            last_token = tokens [idx - 1]\n",
        "            insert_link (first_order_markov_chain, last_token, token)\n",
        "\n",
        "            # The second word in a line can only have a first-level\n",
        "            # markov chain since there is only a single word before it\n",
        "            if idx == 1:\n",
        "                continue\n",
        "\n",
        "            # The last pair of word of a line is special. We want\n",
        "            # to chain it with 'END'; to help in finishing a line\n",
        "            # during predicitions\n",
        "            if idx == num_of_tokens - 1:\n",
        "                insert_link (second_order_markov_chain, (last_token, token), END_TOKEN)\n",
        "\n",
        "            # Populate second-order markov chain\n",
        "            second_last_token = tokens [idx - 2]\n",
        "            insert_link (second_order_markov_chain, (second_last_token, last_token), token)\n",
        "\n",
        "    # Convert first-order markov chain to probability values\n",
        "    for word, chain in first_order_markov_chain.items ():\n",
        "        first_order_markov_chain [word] = to_probability (chain)\n",
        "\n",
        "    # Convert first-order markov chain to probability values\n",
        "    for pair, chain in second_order_markov_chain.items ():\n",
        "        second_order_markov_chain [pair] = to_probability (chain)\n",
        "\n",
        "    print ('[STATUS] Successfully built Markov Model on Corpus!\\n')\n",
        "    return list (set (words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFZ-xxmrCts6"
      },
      "source": [
        "### Section-2.4: Helpers Functions for using the Markov Model for Text-Generation from the Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gx3hEwICts6"
      },
      "outputs": [],
      "source": [
        "# Pick next word from the second-order markov chain. It should be the\n",
        "# highest probability one. If multiple such words exist, randomly pick one\n",
        "def predict_next_word (key, dictionary, debug = False):\n",
        "    max_probability = 0.0\n",
        "    most_probable_words = []\n",
        "\n",
        "    for next_word, probability in dictionary.items ():\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            most_probable_words = [next_word]\n",
        "        elif max_probability - probability < FLOAT_DELTA:\n",
        "            most_probable_words.append (next_word)\n",
        "\n",
        "    if debug: print (key, most_probable_words)\n",
        "    return random.choice (most_probable_words)\n",
        "\n",
        "# Randomly pick a word that can follow; from the first-order markov chain\n",
        "def pick_next_word (key, dictionary, debug = False):\n",
        "    if debug: print(dictionary)\n",
        "    return random.choice (list(dictionary.keys()))\n",
        "\n",
        "# Generate text based on corpus\n",
        "def write_line (start_word, markov_chain_one, markov_chain_two):\n",
        "    line = []\n",
        "    word = start_word.lower ()\n",
        "\n",
        "    if word not in markov_chain_one.keys ():\n",
        "        return 0\n",
        "\n",
        "    line.append (word)\n",
        "    next_word = pick_next_word (start_word, markov_chain_one [start_word])\n",
        "    line.append (next_word)\n",
        "\n",
        "    n = 0\n",
        "    while n < MAX_LINE_LENGTH:\n",
        "        next_next_word = predict_next_word ((word, next_word), markov_chain_two [(word, next_word)])\n",
        "\n",
        "        if next_next_word == END_TOKEN:\n",
        "            return ' '.join (line)\n",
        "\n",
        "        word = next_word\n",
        "        next_word = next_next_word\n",
        "        line.append (next_next_word)\n",
        "        n += 1\n",
        "\n",
        "# Write a Shakespeare play of given length\n",
        "def write_play (hints, mc1, mc2):\n",
        "    string_generated = \"\"\n",
        "    for word in hints:\n",
        "        line = write_line (word, mc1, mc2)\n",
        "        if (line):\n",
        "          line += \"\\n\"\n",
        "          string_generated += line\n",
        "    return string_generated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEXeFcxCCts7"
      },
      "source": [
        "### Section-2.5: User API for Text Prediction Given a Sequence of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OLjpnCfiCts7"
      },
      "outputs": [],
      "source": [
        "def predict_next (sequence, mc1, mc2):\n",
        "    # Sanity checks\n",
        "    sequence = sequence.strip ()\n",
        "    if (sequence == \"\"):\n",
        "        raise ValueError('Sequence must not be an empty string. Please retry!')\n",
        "\n",
        "    tokens = tokenize (sequence)\n",
        "    line = ''\n",
        "    for token in reversed (tokens):\n",
        "        line = write_line (token, mc1, mc2)\n",
        "\n",
        "        if line:\n",
        "            break\n",
        "\n",
        "    return line + \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rm_YyajCts7",
        "outputId": "760311e2-c316-45b3-ead3-44e58cc36eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STATUS] Successfully built Markov Model on Corpus!\n",
            "\n",
            "CPU times: user 6.78 s, sys: 73.7 ms, total: 6.86 s\n",
            "Wall time: 6.98 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# This is the first order markov chain. It chains a word\n",
        "# with the word(s) that can come after it\n",
        "mc_odr1 = {}\n",
        "\n",
        "# This is the second order markov chain. It chains a pair\n",
        "# of words with word(s) that can follow it\n",
        "mc_odr2 = {}\n",
        "\n",
        "words = build_markov_model (lines, mc_odr1, mc_odr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1oOmT-6Cts7",
        "outputId": "9778be65-b0cb-400d-e56a-8eebe1163bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "góc bình yên\n",
            "bấm mòn cả chân mây cuối trời\n",
            "tạ ê chề nỗi đau trong lòng\n",
            "nam đã được ghi nét vinh danh\n",
            "bổng thanh tao câu từ mộc mạc chân quê\n",
            "chiêm lả lướt gió ngàn khơi trập trùng\n",
            "cớ chỉ rình hờn ghen với đò đêm ngày\n",
            "giọt tuôn não nề tâm can\n",
            "mưu con người có nhớ không\n",
            "vốn người tâm huyết thiết tha mặn nồng\n",
            "sợi ngất ngây tình đời\n",
            "với trái địa đàng mộng mơ\n",
            "trinh nương\n",
            "chim ơi nắng lớn to thế này\n",
            "mướp gánh dưa người quê xa mẹ hiền\n",
            "một kiếp người\n",
            "mồ trầm luân\n",
            "chị khâu nỗi buồn\n",
            "bước ngày xưa\n",
            "lững liêu xiêu bóng mẹ già\n",
            "dậu mồng tơi nghe mòn mỏi đợi chờ\n",
            "bận người ơi có biết không\n",
            "thủy bấy lâu nay ông táo về trời\n",
            "gếch lên nữa mảnh trăng thề năm xưa\n",
            "mùi tin người dạ thưa trăm năm\n",
            "cha trọn đời\n",
            "trống đồng đánh thức muôn ngàn nhớ nhung\n",
            "quí của ông cha giữ gìn\n",
            "mặt ao\n",
            "bão cưa gẫy cành ngày nay\n",
            "người sỉn say cờ bạc phát triển vững bền\n",
            "ngã đau\n",
            "vũ trôi xuân thì đã muộn màng\n",
            "giấc mộng vàng\n",
            "buôn rèm nở hoa\n",
            "đốt nhà này bấy lâu nay quê hương\n",
            "thầy hôm nay ngày lễ tình nhân gian\n",
            "đem hồn thơ là tiếng nói tiếng yêu thương\n",
            "hoài thân em như một giấc mơ\n",
            "mùa bàn tay mẹ gói vô thường\n",
            "\n"
          ]
        }
      ],
      "source": [
        "play_length = 150\n",
        "hints = [random.choice (words) for x in range (play_length)]\n",
        "poem = write_play (hints, mc_odr1, mc_odr2)\n",
        "print(poem)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "print(len(re.findall(r'\\w+', poem)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peWtcuWyTH6p",
        "outputId": "46f42573-4b3b-42d1-ecda-52d7ce0517e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch\n",
        "from evaluate import load\n",
        "from collections import defaultdict\n",
        "from nltk.util import ngrams\n",
        "\n",
        "\n",
        "def compute_perplexity(all_texts_list):\n",
        "    torch.cuda.empty_cache()\n",
        "    perplexity = load(\"perplexity\", module_type=\"metric\")\n",
        "    # max sequence length and batch size are limited to 256 and 2, respectively, to avoid OOM bug\n",
        "    resized_all_texts_list = [text[:256] for text in all_texts_list]\n",
        "    results = perplexity.compute(predictions=resized_all_texts_list, model_id=\"vinai/bartpho-word\", device='cuda', batch_size=2)\n",
        "    return results['mean_perplexity']\n",
        "\n",
        "def compute_wordcount(all_texts_list):\n",
        "    wordcount = load(\"word_count\")\n",
        "    wordcount = wordcount.compute(data=all_texts_list)\n",
        "    return wordcount['unique_words']\n",
        "\n",
        "\n",
        "def compute_diversity(all_texts_list):\n",
        "    ngram_range = [2, 3, 4]\n",
        "\n",
        "    tokenizer = spacy.load(\"en_core_web_sm\").tokenizer\n",
        "    token_list = []\n",
        "    for sentence in all_texts_list:\n",
        "        token_list.append([str(token) for token in tokenizer(sentence)])\n",
        "    ngram_sets = {}\n",
        "    ngram_counts = defaultdict(int)\n",
        "\n",
        "    metrics = {}\n",
        "    for n in ngram_range:\n",
        "        ngram_sets[n] = set()\n",
        "        for tokens in token_list:\n",
        "            ngram_sets[n].update(ngrams(tokens, n))\n",
        "            ngram_counts[n] += len(list(ngrams(tokens, n)))\n",
        "        metrics[f'{n}gram_repitition'] = (1 - len(ngram_sets[n]) / ngram_counts[n])\n",
        "    diversity = 1\n",
        "    for val in metrics.values():\n",
        "        diversity *= (1 - val)\n",
        "    metrics['diversity'] = diversity\n",
        "    return metrics\n",
        "\n",
        "list_of_string = []\n",
        "# generate words\n",
        "n = 256\n",
        "for i in range(150):\n",
        "    play_length = 150\n",
        "    hints = [random.choice (words) for x in range (play_length)]\n",
        "    poem = write_play (hints, mc_odr1, mc_odr2)\n",
        "    list_of_string.append(poem)\n",
        "list_of_string = [i.replace(\"\\n\", \".\") for i in list_of_string]\n",
        "print(list_of_string[0])\n",
        "list_of_string = list(filter(lambda a: a != \" \", list_of_string))\n",
        "\n",
        "perplexity = compute_perplexity(list_of_string)\n",
        "wordcount = compute_wordcount(list_of_string)\n",
        "diversity = compute_diversity(list_of_string)\n",
        "print(\"Perplexity:\", perplexity)\n",
        "print(\"Wordcount:\", wordcount)\n",
        "print(\"Diversity:\", diversity)\n"
      ],
      "metadata": {
        "id": "jLqBPp2DCv2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "4c92415245794a369ae0485edb4430c1",
            "7fb9a704d0c0457cac9dc393afaa80d8",
            "8f2b785d4b0b4f9eb213edaa8d3d5e5d",
            "1260984fa71748e5944be41749c787c2",
            "f177ea644b3f4234bde22c805e72eb77",
            "390173fc214342679f2343c61621bba1",
            "d1a85482af0d4d8e860f10d433cd2321",
            "3f5b3b9599e54a6e8850421f507d2857",
            "ebf92cedb59c400994a3f0c89540cb76",
            "f94523eb78b84800ab7040690d30f70b",
            "b0a626e4810b4e5980a6daf36b252a2a"
          ]
        },
        "outputId": "4f0f5ff6-b16f-419c-89e8-25337f8aa5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "từng chuổi gió đeo nụ tình.lệnh ta ngồi bên nhau.tuần súc lăn đá ném tưng bừng đón xuân.bần lắm thay.nhốt hồn thơ là tiếng nói tiếng yêu thương.úi trời mới được thảnh thơi.rào mênh mang đất trời.vắng dễ ta quên hết những lời yêu thương.thoi mới còn thiếu những điều viển vông.ngàn ra về lòng mãi ngất ngây tình đời.ngay cha về với những ngày bên nhau.chúa thật là đáng yêu.quân người vợ yêu thương.mủi lòng.sống phù du.mít càng tương tư.xấu vẫn không quên.lë ra thì đã muộn màng.trơ cây.canh tàng đếm từng giọt đắng gõ tâm tư.bồng say sưa trong nỗi nhớ mong.nỗi mịt mù.dắt con đi khắp mọi miền quê ta.xin chắp tay con gái nhà quê hương.khoảng bình yên.trần nữ nhi khuê các nguyện thân đợi chờ.chuyện khơi đầy niềm vui.ngược long đong một đời.huế xinh tươi dịu dàng nét xuân.cải còn non còn đọng lại bên nhau.nỗi cách chia để em được bình an.màn chơi trốn tìm ngày xưa.thoáng hình hài của cha ông.muôn nhí nhảnh nết na dịu dàng nét xuân.châu không gian tĩnh lặng cô đơn.thưởng hương trà men tửu ta dìm tương tư.đề đa tuổi thơ.gió trót bẻ đôi nỗi niềm.xuyên bám trụ một mình ta với mình.quen dần nếp xưa nhọc nhằn.quốc sử sẽ mãi bên nhau.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bartpho-word were not used when initializing MBartForCausalLM: ['encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.10.self_attn.out_proj.bias', 'encoder.layers.6.self_attn.q_proj.weight', 'encoder.layers.6.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.8.self_attn.q_proj.weight', 'encoder.layers.6.self_attn.k_proj.bias', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.10.self_attn.k_proj.bias', 'encoder.layers.10.self_attn.k_proj.weight', 'encoder.layers.11.self_attn.q_proj.bias', 'encoder.layers.4.fc2.bias', 'encoder.layers.6.fc2.weight', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.6.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.8.self_attn.k_proj.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.7.self_attn.k_proj.bias', 'encoder.layers.3.fc2.bias', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.embed_tokens.weight', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.11.fc1.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.9.self_attn.v_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.8.self_attn.k_proj.weight', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.9.self_attn.q_proj.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.8.fc1.bias', 'encoder.layers.8.fc2.weight', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.9.self_attn.k_proj.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.11.fc2.bias', 'shared.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.0.fc2.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn.q_proj.bias', 'encoder.layers.9.self_attn.out_proj.bias', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.7.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.7.self_attn.v_proj.bias', 'encoder.layers.6.self_attn.k_proj.weight', 'encoder.layers.8.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.9.fc1.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.7.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.8.fc2.bias', 'encoder.layers.1.fc1.bias', 'encoder.layers.11.fc1.weight', 'encoder.layers.9.fc1.weight', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layernorm_embedding.bias', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.2.fc2.bias', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.6.self_attn.v_proj.weight', 'encoder.layers.0.fc1.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn.q_proj.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.7.fc1.weight', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.9.self_attn.v_proj.weight', 'encoder.layernorm_embedding.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.fc1.weight', 'encoder.layer_norm.bias', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.8.self_attn.v_proj.weight', 'encoder.layers.7.self_attn.v_proj.weight', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.fc1.bias', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.8.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.out_proj.weight', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.11.self_attn.k_proj.weight', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.7.fc1.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.6.fc1.bias', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.7.fc2.bias', 'encoder.layers.9.fc2.bias', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.embed_positions.weight', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.6.self_attn.out_proj.bias', 'encoder.layers.10.self_attn.v_proj.bias', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.6.self_attn.q_proj.bias', 'encoder.layers.10.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.10.fc1.weight', 'encoder.layers.4.fc1.weight', 'encoder.layers.9.self_attn.k_proj.weight', 'encoder.layers.10.self_attn.q_proj.weight', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.7.fc2.weight', 'encoder.layers.10.fc2.weight', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.10.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layer_norm.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.11.self_attn.v_proj.weight', 'encoder.layers.7.self_attn.out_proj.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.11.self_attn.out_proj.bias', 'encoder.layers.6.fc2.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.9.self_attn.out_proj.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.9.self_attn.q_proj.bias', 'encoder.layers.8.self_attn.q_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn.out_proj.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.11.self_attn.v_proj.bias', 'encoder.layers.10.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.9.fc2.weight', 'encoder.layers.8.self_attn.out_proj.bias', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.fc1.weight', 'encoder.layers.5.fc1.weight', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.11.fc2.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.10.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.11.self_attn.k_proj.bias', 'encoder.layers.7.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.v_proj.weight']\n",
            "- This IS expected if you are initializing MBartForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MBartForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c92415245794a369ae0485edb4430c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 4099.416478678386\n",
            "Wordcount: 2865\n",
            "Diversity: {'2gram_repitition': 0.31836767851823766, '3gram_repitition': 0.19456755213572963, '4gram_repitition': 0.0977094651778645, 'diversity': 0.49536543406041506}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ3LV_w_EcIb",
        "outputId": "04b5c919-1d78-47b7-b36b-e0258bb1b591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgpUO-fYCts8"
      },
      "source": [
        "Following code demonstrates **text prediction given a sequence**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6-ZIyGpGyTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c92415245794a369ae0485edb4430c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fb9a704d0c0457cac9dc393afaa80d8",
              "IPY_MODEL_8f2b785d4b0b4f9eb213edaa8d3d5e5d",
              "IPY_MODEL_1260984fa71748e5944be41749c787c2"
            ],
            "layout": "IPY_MODEL_f177ea644b3f4234bde22c805e72eb77"
          }
        },
        "7fb9a704d0c0457cac9dc393afaa80d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390173fc214342679f2343c61621bba1",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a85482af0d4d8e860f10d433cd2321",
            "value": "100%"
          }
        },
        "8f2b785d4b0b4f9eb213edaa8d3d5e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f5b3b9599e54a6e8850421f507d2857",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebf92cedb59c400994a3f0c89540cb76",
            "value": 75
          }
        },
        "1260984fa71748e5944be41749c787c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f94523eb78b84800ab7040690d30f70b",
            "placeholder": "​",
            "style": "IPY_MODEL_b0a626e4810b4e5980a6daf36b252a2a",
            "value": " 75/75 [00:07&lt;00:00, 10.19it/s]"
          }
        },
        "f177ea644b3f4234bde22c805e72eb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390173fc214342679f2343c61621bba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a85482af0d4d8e860f10d433cd2321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f5b3b9599e54a6e8850421f507d2857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf92cedb59c400994a3f0c89540cb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f94523eb78b84800ab7040690d30f70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a626e4810b4e5980a6daf36b252a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}